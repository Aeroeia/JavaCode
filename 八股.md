## 八股

### GC

**介绍一下jvm的垃圾回收吧**

> jvm的内存区域可以粗略划分为堆区、方法区、栈区 其中堆区是引起垃圾回收的主要因素 传统的堆区可以划分为新生代和老年代两个区域 而像G1和后面一些新的垃圾回收器则划分为一个个小的region 当新生代的Eden区内存不足的时候出触发minorgc 回收新生代中的内存空间 当大对象创建、新生代对象晋升等原因导致老年代的内存空间不足的时候触发fullgc 回收整个jvm的内存空间 
>
> 而垃圾回收大致可分标记和清理阶段  其中标记算法常用的有引用计数法和可达性分析法 引用计数法就是在每个对象对象头记录引用的次数 当引用为0的时候进行回收 这种算法实现起来比较复杂 要考虑并发安全等因素而且当对象循环依赖时就无法被回收 另外一种主流的就是可达性分析法 从gcroot出发遍历对象中的引用从而标记出所有可达的对象 jvm虚拟机栈中的对象、本地方法栈的对象、方法区中引用的常量对象都可作为gcroot 
>
> 垃圾回收细分点又可分为为串行、并行、并发回收 像serial parnew这种垃圾回收器采用的就是串并行回收机制 在垃圾回收阶段全程STW而CMS G1这样的垃圾回收器则是并发回收 CMS的回收步骤可以分为以下几步：分别是初始标记、并发标记、再标记、清理  然后初始标记阶段是STW 用于标记gcroot 然后是并发回收阶段 这个阶段通过三色标记法和读写屏障标记出可达的对象 然后是再标记阶段 这个阶段是STW 主要是为了解决漏标的问题 会对remember_set 脏卡、以及gcroot进行检查 然后就是STW的清理阶段了
>
> G1的垃圾回收算法和CMS类似 主要不同点是基于region进行回收的 在初始标记阶段同时标记gcroot所在的region 因为region中有会有一个remember_set记录被其他region引用 扫描每个region看时候被gcrootregion引用并标记 并发标记只遍历这些被标记的region 缩小了遍历范围 然后再标记阶段和CMS类似 不过采用的是SATB算法 清理阶段CMS采用的是标记整理算法 而GC采用的是复制算法

介绍

https://www.bilibili.com/video/BV1Di421f7Y6/?spm_id_from=333.337.search-card.all.click&vd_source=fd0b7243ae5b04e4d46b23923b639f5b

G1

https://www.bilibili.com/video/BV13J411g7A1/?spm_id_from=333.1387.homepage.video_card.click&vd_source=fd0b7243ae5b04e4d46b23923b639f5b

| 回收期            | 代           | 算法              | STW           | 目标         | 是否弃用          |
| :---------------- | ------------ | ----------------- | ------------- | ------------ | ----------------- |
| Serial            | 新生代       | 复制              | 全程 STW      | 简单、客户端 | 否                |
| Serial Old        | 老年代       | 标记-整理         | 全程 STW      | 配合 Serial  | 否                |
| ParNew            | 新生      代 | 复制              | STW（多线程） | 配合 CMS     | 否（但 CMS 已弃） |
| Parallel Scavenge | 新生代       | 复制              | STW（多线程） | 高吞吐       | 否                |
| Parallel Old      | 老年代       | 标记-整理         | STW（多线程） | 高吞吐       | 否                |
| CMS               | 老年代       | 标记-清除         | 仅少量 STW    | 低延迟       | ✅（JDK 14+ 移除） |
| G1                | 全堆         | 标记-整理（局部） | 部分 STW      | 可预测停顿   | 否                |
| ZGC               | 全堆         | 并发整理          | 极低 STW      | 超低延迟     | 否                |
| Shenandoah        | 全堆         | 并发整理          | 极低 STW      | 超低延迟     | 否                |

**标记手段：**

- 可达性分析

  > 从根节点出发并根据根节点对象中引用的对象进行延伸
  >
  > 可作为根节点的对象：
  >
  > - 虚拟机栈中引用的对象
  > - 本地方法栈引用的对象
  > - 静态引用的对象
  > - ~~方法区引用的常量对象~~

- 引用计数法

  > 为每个对象分配引用计数器 被引用+1 失效-1 但是出现循环依赖且两个对象都不被外部引用时无法被清理

**三色标记法**

- 白色：未被标记
- 灰色：自身被标记但是拥有的成员变量未被标记
- 黑色：自身被标记所拥有的成员也被标记 ==只管自己拥有的 孙子辈的不管==

**读屏障&写屏障**

- 多标

  ![image-20251112162319301](assets/image-20251112162319301.png)

  > ==A==-**C**-E A被黑色标记、 B灰色标记 C白色标记 如果在标记完后A和C的引用断开 那么C就不会被回收 

- 漏标

  ![image-20251112162336269](assets/image-20251112162336269.png)

  > **发生条件：**
  >
  > - 新增了黑色对象到白色对象的引用
  > - 删除了灰色对象对白色对象的引用
  >
  > 新增的A-E的连接 但是E在先前的可达性分析中没被标记 因此导致错误清除了E ==严重影响程序运行==
  >
  > ==发生这种情况的原因是线程还没扫描到E 但是这时候C就删除了E的引用同时A对E新增了引用==

- 漏标解决方法

  CMS：增量更新

  > - 写屏障
  >
  > 相当于Spring的拦截器 在改变引用时加入一个写屏障，这个屏障并非真的屏障 只不过是加了一段逻辑 在更改引用时直接将被引用的对象改为灰色
  >
  > - 读屏障
  >
  > 在检测到读白色对象时，将对象改为灰色
  >
  > ==这两种都是针对以上漏标的情况==

  G1: SATB

  > - SATB算法
  >
  > 在删除引用关系前 将被删除的引用关系记录下来 最后沿着这些旧引用的根重新扫描一遍
  >
  > ==在前面的情况中如果A是root 那么不会触发写屏障 因为写屏障只发生在堆区中对象引用发生改变 而root通常不是堆对象 因此引入SATB算法==

| `obj.field = x` | **写入堆** | **写屏障**     | 修改堆中对象的字段值   |
| --------------- | ---------- | -------------- | ---------------------- |
| `x = obj.field` | **读取堆** | **读屏障**     | 从堆中对象的字段读取值 |
| `x = y`         | **栈操作** | **通常不触发** | 两个局部变量之间的赋值 |

**分代**

> 分代的好处就是可以根据堆的大小选择不同的清理算法 比如小对象 Eden、S0、S1区可以用复制算法 空间损耗不会太大 而且清除效率高且不会产生内存碎片 老年代大内存区域使用标记整理算法 对空间利用率高

**代际间引用关系**

> 每次gc扫描的时候并不是全堆扫描 而是新生代和老年代分开 Eden区满了触发一次新生代扫描频率较高 而当老年代空间不足才出发fullgc 频率较低 这种代际引用就会出现漏标情况 
>
> 老年代引用了新生代 通过写屏障将这个引用记录到remembered_sets中 minorgc的时候以这些老年代对象作为gcroot进行扫描

**垃圾回收流程**

1. 初始标记

   > 标记gcroot

2. 并发标记

   > 从gcroot出发并发进行标记

3. 再标记

   > - 再次检查扫描gcroot 对这些新的gcroot进行扫描标记
   >
   >   **因为并发标记期间 Roots 可能新增引用 无法出发写屏障**
   >
   > - 并发标记期间，如果老年代对象的字段被修改（如 `A.field = B`），对应的 Card 会被标记为 dirty。
   >
   > - remeber_set中的对象 解决代际引用
   >
   > STW	

4. ### 回收

   > | **CMS** | **并发清理**（Concurrent Sweep） ✅**无需 STW** | 标记-清除（Mark-Sweep） 直接回收不可达对象的内存        |
   > | ------- | ---------------------------------------------- | ------------------------------------------------------- |
   > | **G1**  | ✅**Mixed GC 是 STW**（但可增量）               | 标记-整理（Mark-Compact） 回收选定的 Young + Old Region |

**增量算法**

> 增量算法是早期改善串行/并行gc(标记和清理都是STW) 引入的 而现代多采用初始标记-并发标记-再标记-清理这种模式

**g1**

![image-20251112215350145](assets/image-20251112215350145.png)

**remember_set：记录其他region引用当前region**

**collection_set:本次gc需要清理的region集合**

**MixGC：**

> - 初次标记：标记gcroot和所在==region==  STW
> - 扫描old区region看是否被rootregion直接引用并标记 基于rset
> - 并发标记 只需要遍历第二步中被标记region中的对象
> - 再标记 只不过用SATB STW
> - 复制清理 ==只选择垃圾量较多的region==

![image-20251112220554255](assets/image-20251112220554255.png)

------

### 双亲委派

> 全包名都相同的一个类被不同的类加载器加载会被判定为不同类 这就使得开发维护非常困难 这是双亲委派引入的一重大原因原因 同时也保证安全性 比如通过自定义类加载器加载java.lang.String 绕过了一些api的安全检查 

![image-20251113113440636](assets/image-20251113113440636.png)

**打破双亲委派**

> 继承了ClassLoader并重写loadClass 加载一个现有的类 进行比较这同一个类结果是false 是因为重写的loadClass不会去从父亲类加载器开始查找而是直接加载 就打破了双亲委派 存在这种机制是因为这个方法在很早之前就有了 而双亲委派机制是后续引入的 而JDK为了向下兼容便保留了 重写findClass就符合双亲委派了

![image-20251113182559348](assets/image-20251113182559348.png)

**第二种双亲委派的破坏**

> 比如在加载各种数据库jdbc驱动类的时候 bootstrap加载器不可能对每个驱动都有对应实现 因此jdk提供接口让数据库厂商按照这个规范进行实现 通过SPI机制发现这些驱动类并通过ApplicationClassLoader加载 从而导致上层加载器依赖下层加载器破坏双亲委派

------

### 吞吐量

**吞吐量 = 并发量 / 响应时间** 

> QPS = Concurrency / Response_Time

并发量最大值由系统资源决定（CPU、IO、内存、网络）

------

### MQ

#### Kafka

> Kafka的每个节点是一个个broker一般部署在集群的不同服务器中 每个broker中可以有多个分区 topic通过调度器将消息分发到不同的分区中使得每个分区负载均衡 消费者分为消费者组和消费者 消费者组通过offset消费分区中的消息 多个分组可以读取同一条消息 而消费者组中只能有一个消费者消费同一条消息 当同一消费者组的消费者数和topic下的分区数量一致时每个分区的消息都能同时被对应的消费者消费 消费者数小于分区数时则会有某个消费者一次性拉取多个分区消息 当消费者数大于分区则会有某些消费者闲置 topic-patition-consumer_group对应的元信息和调度器由zookeeper管理 新版kafka由内部基于Raft算法的controller管理

准确版

> Kafka 集群由多台 broker 构成。
> Topic 下有多个 partition，每个 partition 存储在不同 broker 上，由 producer 通过 partitioner 分配消息。
>
> 消费者以 consumer group 为单位消费消息：
>
> - 一个 partition 同时只能被同一组的一个消费者消费
> - 消费 offset 按 group 隔离存储
> - consumer 数 <= partition 数才能实现最大并行度
>
> 多个 consumer group 可重复消费同一条消息（广播效果）。
>
> 元数据管理：
>
> - 旧版 Kafka 使用 Zookeeper 管理元数据与 controller 选举。
> - 新版 Kafka 使用内部 KRaft（Raft algorithm）替代 Zookeeper。
>
> ==Offset 从 Kafka 0.9 起存储在内部 topic：__consumer_offsets。 这个是集群 有多个副本保证高可用==
>
> ==kafka controller可以独立部署也可以在某个broker中管理 其他broker存元信息副本==
>
> ==对于每个Consumer Group都会有Consumer Group Coordinator负责 只负责consumer的调度 这个调度器不一定和group在同一broker==
>
> kafka的topic元数据在controller主节点中 但是每个broker都会有副本 发送消息/消费消息的时候访问随机一个broker获取到topic下的分区后在客户端做缓存
>
> ==topic分发给partition：如果指定了key 则根据Hash取模 否则轮询 rocketmq是轮询==

**“topic 通过调度器将消息分发到分区，为负载均衡”**

✔ 基本正确，但可以更精确：

**生产者（producer）在发送消息时根据 partitioner 决定目标分区**：

- 如果指定 key → hash(key) % partition_count
- 如果没有 key → 轮询（round-robin）
- 或者用户自定义 partitioner

⚠ Kafka broker 本身不负责“调度消息到 partition”，是 **producer 决定**。



**“topic-partition-consumer_group 的元信息和调度器由 zookeeper 管理”**

⚠ **旧版 Kafka（< 2.8）才是这样**，但不完全准确：

**Zookeeper 管理的是：**

- broker 列表
- controller 选举
- topic 配置、分区信息
- ISR 信息（同步副本列表）

**而 consumer offset 在不同版本中有差异：**

| Kafka 版本 | offset 存储在哪                        |
| ---------- | -------------------------------------- |
| < 0.9      | Zookeeper                              |
| ≥ 0.9      | Kafka 内置 topic：`__consumer_offsets` |

🔸 当前主流 Kafka（2.x / 3.x）已经不把 offset 放 ZK 了。

------

#### RocketMq

对比kafka：

- 采用NameServer作集群管理 取代kafka中的zookeeper rocketmq是先访问nameserver再定位到具体的broker
- kafka的patition改名为queue kafka中的partition存放完整消息 而==queue只存放简要消息比如消息的索引位置== ==而完整消息存放到一个commitlog中 offset存于broker当中记录每个队列读到哪了==  这样设计的好处是为了消除多文件编写带来的性能降低（虽然kafka每个patition文件都是顺序写 但是同时写多个文件要查找多次性能损耗） 
- 简化备份模型： kafka==以patition为单位进行主从复制== 而rockermq==以broker为单位== 同步commitlog和queue的内容
- kafka中一个topic下的patition可以在不同broker 而rocketmqtopic下的==queue和topic在同一broker==
- 对消息分类进行了细化 ==支持根据tag过滤消息== 通过hash查找tag 而queue底层是数组可以迅速定位 同一消费者组的不同消费者指定不同的tag 那这个消费者组的offset会乱 是不允许同一消费者组的消费者指定不同tag的
- 支持事务 kafka只保证要么消息同时发送成功要么失败 而rocketmq通过半消息机制可以使得生产者中业务逻辑和发送消息这两件事要么同时成功要么失败 ==半消息机制+回调函数+回查机制==  确认成功后才将消息推送给消费者 ==kafka没有这种机制 可以通过发送一条补偿消息进行回滚==

![image-20251115182837009](assets/image-20251115182837009.png)

==当提交RocketMQLocalTransactionState.UNKNOWN会回查==

- 有原生的延迟队列和死信队列 延迟队列：==定期扫描将消息从延迟索引队列移动到真正的 Topic/Queue== 
- rocketmq有==广播模式== 同一消费者组下的消费者都可以消费同一条消息
- 都支持批量发送（消息存入集合然后发送自动转为批量发送）和批量消费 （kafka使用List接收并设置batch为true rocketmq在listener中修改batchSize）
- 消息Id：Kafka没有全局id 配置生成id的话Kafka时partition局部的 而RocketMq通过机器IP + PID + 生产时间 + Partition/Queue ID算出全局id

==那么kafka是通过Coordinator分配消息 Coordinator广播给消费者负责哪些分区 而rocketmq是消费者自己计算==

**为什么kafka有更大吞吐量**

| 原因                   | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| **批量发送优化更成熟** | Kafka Producer 可以高度批量化（batch.size / linger.ms），一次性写入磁盘和网络；RocketMQ 默认消息发送可能是逐条或者小批量 |
| **索引跳转开销**       | RocketMQ CommitLog + Queue 索引机制，消费时需要通过索引找到消息偏移，增加内存和 CPU 开销；Kafka Partition 直接顺序读取 offset |
| **副本机制灵活**       | Kafka 可以通过 `acks=0/1/all` 配置，牺牲副本一致性换吞吐量；RocketMQ Master/Slave 同步模式通常需要等待 Slave 确认 |
| **批量压缩**           | Kafka 支持 batch 压缩（gzip/snappy/lz4/zstd），减少磁盘和网络 I/O；RocketMQ 默认压缩对吞吐优化有限 |
| **架构轻量**           | Kafka 的 Partition log 是纯顺序写，逻辑简单；RocketMQ 为支持事务、延迟队列、顺序消息，引入了索引表和额外处理逻辑 |

> 可以理解为：RocketMQ 支持零拷贝，但 Kafka 在 **整体写入、读取、批量处理、压缩和副本策略** 上做了更极致的吞吐优化，所以在极限性能上仍然比 RocketMQ 高

------

#### 幂等性

**怎么保证消息的幂等性**

- 幂等锁

  > 用户可能在下单、注册、发表评论等业务下段时间提交多次 可以通过幂等锁保证规定时间内只有一个提交能生效

- 记录消息id

  > 消费消息时在数据库记录消息id 每次消费前检查这个消息是否被消费过

- 设置业务字段唯一保证幂等

  > 比如在订单业务中 通过唯一订单编号控制消息幂等

- 乐观锁

  > 使用版本号或时间戳来检查数据是否已被其他操作修改过。在更新数据时，如果版本号或时间戳与预期的不符，则拒绝更新并返回冲突信息。这样，即使多次尝试更新相同的数据，也只有一次会成功  ==比如自增操作==

------

#### 可靠性

**怎么保证消息可靠性**

- 生产者发送消息到mq

  > 这个过程可能因为broker宕机、网络等原因没有发送成功 
  >
  > 解决方法：
  >
  > Kafka：
  >
  > - 配置ack = -1
  >
  >   - ack = 0 消息发送后则视为成功 最不可靠
  >   - ack = 1 默认机制 等待写入leader分区成功则返回 不等待副本
  >   - ack = -1 等待所有isr写入完成才返回成功 isr意思是能跟上leader数据的副本 即消息没有落后太久的副本 能及时拉取leader消息则进入isr名单
  >
  >   ==以上都是写入内存则视为成功==
  >
  > - 重试机制
  >
  >   - 配置好重试次数
  >
  > - 回调机制
  >
  >   - kafka是异步发送 可以设计回调函数 在结果返回时执行对应的回调函数 重试仍失败时进入回调
  >
  > RocketMq
  >
  > - 发送方式
  >   - 同步发送 发送失败执行对应逻辑
  >   - 异步发送 写好对应回调函数逻辑 在失败时进行相应处理
  >   - 单向发送 发送后不做处理 这种不可靠
  > - 重试机制
  >   - 配置好重试
  > - 事务
  >   - 当发送方出现错误时 通过事务回滚已经发送到broker的那条消息

- mq内部

  > 通过消息持久化、集群机制可以一定程度上确保消息可靠，但是也可能因为mq宕机但是消息未刷盘、主从切换导致消息丢失等，最好的解决办法就是发送消息前和消费消息时进行日志记录 进行对账补偿

- 消费者消费

  > 可能消费者没消费成功就返回ack，可以通过手动ack解决 即处理完成后再返回ack 失败则进行重试 
  >
  > - kafka通过offset控制 
  >
  > - 而rocketmq有内置重试队列 消费者订阅这个队列（这种机制能避免阻塞正常消息消费） 重试次数过多 默认16次后发送到死信队列
  >
  > 二者都没本地重试机制

------

#### Rebalance

- Kafka由事件驱动rebalance 当成员变化时（broker、partition、consumer）进行
- RocketMq由事件驱动+定时触发（20s）

**问题**

- 所有消费者消费暂停 导致消息延迟、消息堆积
- 可能重复消费 当消费中offset未提交进行了rebalance
- 资源浪费、频繁rebalance造成雪崩

------

#### 消息顺序性

- Kafka指定key使消息分法到同一个分区中 消费者采用单线程方式消费 开启幂等性（幂等性维护一个pending队列 会暂存序列号大于期望值的消息 因此当消息延迟也可以保证顺序性 ABC不会因为A的延迟变成BCA）
- RocketMq通过syncsendOrderly方法指定好要发送的队列 消费者消费模式改为顺序消费并进行单线程消费

------

### Netty

> 我现在对netty的理解是这样的：
>
> tomcat的NIO实现是 由一个线程通过IO多路复用接收连接请求和连接发送的数据 如果是请求的连接则创建对应的socket进行接收 如果是数据的接收则将其读取后通过异步线程处理 但是当线程池满了就会导致接收线程也卡住
>
> 以上是单线程Reactor模型
>
> 而Netty为了解决这种瓶颈以及cpu利用率不高的情况 采用多线程Reactor 将字节流读取和任务分发分开来 主线程负责读取字节流 如果是建立连接的服务则直接创建对应socket准备接收 如果是接收数据的请求 则将读取好的字节流分发给subReactor线程池 再由这个线程池分发给异步线程进行任务的处理 这样就提高了cpu利用率 同时及时任务处理的比较慢 也可以及时接收到请求发来的数据不会导致处理完后才进行数据的读取使响应变慢

**准确版**

> Tomcat 的 NIO 使用的是“单 Reactor + 工作线程池”模型：少量 Poller 线程负责 Accept 与 Read，它们通过 Selector 监听所有连接的 I/O 事件；当读取到请求数据后，把任务交给业务线程池处理，因此如果业务线程池被占满，Poller 的读取处理也会受到影响，导致整体吞吐下降。Netty 则采用“多 Reactor 多线程模型”，将接收连接与处理 I/O 分离：BossGroup 中的线程只负责 Accept，而 WorkerGroup 中多个 NioEventLoop 线程各自持有独立的 Selector，负责它自己管理的连接的 Read/Write，并且直接在事件循环中执行 pipeline 业务逻辑而不依赖额外线程池，从而避免不必要的线程切换，更充分利用多核 CPU，即使某个连接在处理业务也不会阻塞其它连接的 I/O。因此相比 Tomcat，Netty 能够以更低开销处理更高并发并保持更稳定的响应时间。

**BossGroup**

- 只有 accept
- 接收连接并将 SocketChannel 注册到某个 WorkerGroup 的 NioEventLoop

**WorkerGroup**

每个线程：

- 一个独立的 Selector（subReactor）
- 负责：read + decode + pipeline 事件 + write
- 不依赖额外线程池（除非你主动添加）

**Webflux**

> 在等待io逻辑的地方做出了改变 比如mysql redis rpc等 这样业务线程就能快速释放 等结果传回来了再让线程执行

------

### 集合&JUC

#### 集合

##### **List**

**并发不安全**

- ArrayList 基于动态数组 扩容时扩容为自身的1.5倍

  > 之所以扩容是 1.5 倍，是因为 1.5 可以充分利用移位操作，减少浮点数或者运算时间和运算次数
  >
  > int newCapacity = oldCapacity + (oldCapacity >> 1);

- LinkedList 

  > 基于链表 是一个双端链表

**并发安全**

- Vector 

  > 基于动态数组 所有操作加了**synchronized**

- CopyOnWriteArrayList 写时复制 发生写操作时加锁并将旧数组内容拷贝到新数组 读无锁 读旧数组

  > 不采用类似ConcurrentHashMap那样是因为Map结构访问的时候通常只对一个元素修改 而List通过索引 需要顾及全局快照性

- Collections.synchronizedList(list) 

  > 通过Collcetions这个工具类实现加锁版 所有操作都加了锁

**modcount**

> ==Iterator是每次for或手动创建新的== Iterator中的expectmodcount和集合中的modcout是为了确保==并发修改能感知到从而报错== 但是只有使用iterator遍历或者增强for时才会对比这两个字段 通过get方法或者写入时不会比对 也就无法感知到结构被修改 ==目的就是解决“遍历时结构改变导致的二义性问题”== 是一种单线程手段

**JUC下的集合都不采用fail-fast**

> 想做到 100% fail-fast 检测，需要：
>
> - 修改也加锁
> - 遍历也加锁
> - 读写互斥
>
> 这直接破坏 ConcurrentHashMap、ConcurrentLinkedQueue 等集合最关键的特性：
>
> **无锁/低锁、高吞吐、线程间独立操作**

------

##### Map

**并发不安全**

- HashMap

  > 初始容量为16 负载因子0.75 超过capacity*factory则进行两倍扩容 槽位计算公式为
  >
  > ```java
  > h = h.hashcode()^(h>>16);
  > index = (capacity-1)&h
  > ```
  >
  > 在扩容的时候如果容量二进制位高位为1则索引值+旧容量 否则不变
  >
  > JDK1.7及以前对于Hash碰撞的位置采用链表 JDK1.8及以后链表元素>8采用红黑树 <6退为链表
  >
  > 红黑树根据**hash 值大小**排序
  >
  > 如果 hash 相等，用 key 的 `Comparable.compareTo`
  >
  > 如果 key 不是 Comparable，则用**系统的 tie-breaker（System.identityHashCode）**

- LinkedHashMap

  > 继承自HashMap，在此基础上使用双向链表维护了键值对的插入顺序或访问顺序，使得迭代顺序与插入顺序或访问顺序一致 ==在Entry节点中新增了prev next指针==

**并发安全**

- HashTable 

  > 全部操作加锁 负载因子为0.75  count>=length*factor时候扩容为自身两倍 初始容量是11 不是2的幂因此要重新计算索引 ==后面的Map的容量都是2的幂次 采用了位运算转移元素==

- ConcurrentHashMap 

  - 锁机制

    > JDK1.7前采用分段锁 JDK1.8及以后采用CAS+Synchronized进行更新 都是读无锁 通过volatile保证不会读取到一半的值

  - size更新

    > ConcurrentHashMap 的 size 更新使用 LongAdder 思路：
    > 大部分情况下通过 CAS 更新 baseCount；
    > CAS 失败时分散到多个 CounterCell，通过 CAS 或 very small synchronized 来更新。
    > 因此既避免全局锁，又能保持并发写的高吞吐。
    >
    > baseCount
    > CounterCell[]
    > addCount()
    > size()
    >
    > ==size=baseCount + sum(counterCells);==

  - ConcurrentSkipListMap

    > ==并发版TreeMap 如果采用红黑树更新时需要锁住整个树== 基于跳表（每个新增节点时通过随机数确定层数 当随机到的小于0.25就停止）实现 CAS+volatile进行写 读无锁

  - 对比写时复制

    > CopyOnWriteArrayList是因为索引位置改变所以可能导致元素重复读因此采用写时复制 但是Map不会出现这种情况 因为Hash索引位置固定 而且链表是尾部插入不能修改链表结构（交换元素位置） 且通过next指针进行读取 不会导致重复读



------

##### Set

**并发不安全**

- HashSet

  > 基于HashMap实现

- TreeSet

  > 基于TreeMap实现

- LinkedHashSet

  > 基于LinkedHashMap实现

**并发安全**

- ConcurrentSkipListSet

  > 基于ConcurrentSkipListMap

- CopyOnWriteArraySet

  > 底层是CopyOnArrayList 适用于读多写少的情况 元素不重复

------

##### Queue

- ConcurrentLinkedQueue

  > ConcurrentLinkedQueue的实现是入队出队的时候对next不断CAS

- BlockingQueue

  > 阻塞队列有两种实现**ArrayBlockingQueue**/**LinkedBlockingQueue** 入队出队通ReentryLock加锁 take/offer的时候如果没有元素/空间满了会通过await方法挂起线程

------

##### Deque

- LinkedBlockingDeque
- ConcurrentLinkedDeque

------

#### volatile

> volatile是jvm提供的轻量级同步机制 可以保证并发编程三大特性（原子性、可见行、有序性）中的可见行和有序性 主要用两个作用
>
> - 防止指令重排
> - 保证多线程下的可见行
>
> **保证可见行：**
>
> - ~~在对volatile变量进行写操作时通过JVM的StoreStore和StoreLoad屏障 会向处理器发送一条lock前缀命令（总线锁指令前缀） 将这个缓存变量写回系统主存 而其他处理器遵循缓存一致性协议 就会将volatile变量从主存重新读回自己工作内存~~
> - **volatile 可见性保证：**
>   1. 对 volatile 变量进行写操作时，JVM 会插入 StoreStore + StoreLoad 内存屏障（Memory Barrier），确保写操作不会被重排序，并强制刷新处理器的 store buffer。
>   2. CPU 通过缓存一致性协议（MESI）广播该缓存行的修改，使其他 CPU 缓存中该行失效（Invalid），从而保证其他 CPU 下一次访问该变量时能读取到最新值。
>   3. 现代 CPU write-back 策略下，volatile 写不一定立即写回主存，但保证通过 MESI 协议，其他线程读到的值一定是最新的。
>   4. volatile 读操作会插入 LoadLoad + LoadStore 屏障，禁止指令重排序，并确保从缓存一致性系统获取最新值，而不是从寄存器或旧缓存读取。
> - 原因不在于 MESI 不存在，而是线程可能：
>   - 读了寄存器里的旧值
>   - 缓存行被延迟刷新
>   - 没有真正发起 memory read
> - voaltile做了以下几点保证可见性
>   - 禁止寄存器缓存 / 强制读写穿透
>   - 写入时刷新 Store Buffer因为Store Buffer 会暂存写操作从而可能是旧值
>
>
> **保证有序性：**
>
> 在volatile写后面加LoadLoad屏障和LoadStore屏障
>
> - LoadLoad屏障禁止volatile下面的读操作和上面的volatile读重排序
> - LoadStore屏障禁止volatile下面的写操作和上面的volatile读重排序
>
> 在volatile操作前插入一个StoreStore屏障在后面插入一个StoreLoad屏障
>
> - StoreStore禁止上面的普通写和volatile写重排序
> - StoreLoad禁止上面的volatile写和下面的读重排序

X86处理器只会对写读重排序 不会对读读、读写、写写重排序 因此只需要在volatile后加一个StoreLoad屏障

==volatile保证可见性 主要是禁止寄存器缓存==

![image-20251117152129752](assets/image-20251117152129752.png)

![image-20251117152138395](assets/image-20251117152138395.png)

------

#### JUC工具类

- ThreadPoolExecutor

  > 线程池

- Executors

  > 工厂类 获取ScheduledThreadPool、FixedThreadPool、CachedThreadPool、SingleThreadExecutor、SingleThreadScheduledExecutor

- CountDownLatch

  > 调用await，达到计数值后放行

- CyclicBarrier

  > 与`CountDownLatch`不同的是，`CyclicBarrier`可以重复使用，当所有线程都通过屏障后，计数器会重置，可以再次用于下一轮的等待

- Semaphore

  > 维护一个许可信号量 线程在访问资源前需要获取许可

- AtomicInteger

  > 提供了对整数类型的原子操作，如自增、自减、比较并交换等

- AtomicReference

  > 用于对对象引用进行原子操作 

- AtomicStampedReference

  > 用于解决ABA问题 通过一个版本号

------

#### **CAS**

> 比较内存中的值是否等于预期值，如果相等就更新为新值，否则什么也不做。
>
> CAS 是 CPU 提供的原子指令
>
> **原子性**
>
> - 在执行过程中这条指令对内存的读-比对-写是不可被打断的
>
> - CAS 写操作通常会带上 **占缓存行 + lock 前缀的总线协议（CACHE LOCKING）不是锁总线** 保证写操作被刷新到缓存一致性系统，让其他 CPU 能看到最新值
>
> **可见性**
>
> - 其他 CPU 对该内存地址的操作会被缓存一致性协议（MESI）协调
>
> ==搭配volatile使用是因为jvm可能指令重排以及寄存器缓存==
>
> | 特性     | CAS 实现方式                                     |
> | -------- | ------------------------------------------------ |
> | 原子性   | 读-比对-写不可被其他线程打断                     |
> | 现代 CPU | 缓存行独占 + MESI 协议（大部分情况无需总线锁）   |
> | 特殊情况 | 跨 CPU 或老架构可能使用 lock 前缀/总线锁         |
> | 可见性   | 通过 MESI 广播/缓存一致性保证其他 CPU 看到最新值 |

------

#### Synchronized

**monitor**

> synchronized是通过jvm内置的Monitor监视器实现的（通过c++的Object.Monitor实现），而这个监视器又依赖于操作系统的互斥锁Mutex实现 在使用synchronized时 编译成字节码的时候会给代码块加上monitor
>
> - 进入代码块加锁 ==monitorenter==
> - 结束代码解锁 ==monitorexit==
>
> monitorenter计数器+1 exit计数器-1 当计数器为0锁释放 等待队列中的线程竞争锁 

**内存语义**

> 内存语义来讲 synchronized 的解锁（monitorexit）通过 Release(**StoreStore StoreLoad**) 内存屏障强制把之前的写从 Store Buffer 刷入缓存，从而触发 MESI 将对应缓存行在其他 CPU 上失效；加锁（monitorenter）的 Acquire(**LoadLoad LoadStore**) 屏障保证后续读取不会使用旧值，因此能够看到最新可见的值。

**等待队列**

> synchronized底层有两个队列 分别是waitSet和entryList
>
> 竞争锁失败的线程进入entryList等待，wait方法等待的线程进入waitSet队列，被唤醒的线程不会直接竞争锁而是加入到entryList等待

**可重入**

> Monitor对象内部维护两个关键字段
>
> - **owner**：当前持有锁的线程（Thread）
>
> - **recursionCount / entryCount**：当前持有锁线程的重入次数

**锁升级**

> - 无锁 对象头空闲 加锁需要CAS
>
> - 偏向锁 对象头MarkWord记录线程ID 偏向于某个线程 这个线程进入无需获取锁 
>
>   | 其他线程如何知道线程 A 是否结束使用偏向锁？ | **无法直接知道**，必须通过 JVM 在安全点检查线程 A 的调用 |
>   | ------------------------------------------- | -------------------------------------------------------- |
>
> - 轻量锁 升级在偏向锁持有时有线程进行竞争锁 不断CAS加锁 Mark Word 指向栈上 Lock Record（用于保存原来的MarkWord便于恢复和重入）==偏向已被撤销，且当前无锁才会升级轻量锁 否则重量锁==
>
> - 重量锁 当两个以上线程竞争锁就会升级 进行阻塞 Mark Word 指向 Monitor 对象（EntryList / WaitSet）
>
> 在jdk1.6版本前是重量级锁，但重量级锁底层是基于操作系统指令mutex互斥锁实现的 涉及内核态和用户态之间的切换 会导致性能下降因此jdk1.6版本之后引入了锁升级策略
>
> 当一个对象处于无锁状态时，第一个线程首次获取锁会通过一次 CAS 将自己的线程 ID 写入对象头的 Mark Word，并将其升级为偏向锁；此后该线程再次进入同步块时，无需任何操作，直接成功，实现零开销重入。如果此时有第二个线程尝试获取该锁，JVM 会触发偏向锁撤销流程，检查原线程是否仍在使用该对象：若原线程已退出，则撤销偏向，对象恢复为无锁状态，新线程可尝试重新偏向（JVM 会根据 **对象竞争历史和偏向锁撤销次数** 来决定）或升级为轻量级锁；若原线程仍在执行，则直接跳过轻量级锁，将锁膨胀为重量级锁（Monitor），并进入阻塞等待。整个过程中，偏向锁和轻量级锁都避免了用户态到内核态的切换，只有在真正竞争激烈时才会使用重量级锁，从而在无竞争场景下实现了极致的性能优化。

```
可偏向无锁（101） 
→ 偏向 A（101 + threadID） 
→ 撤销 → 可偏向无锁（101） 
→ B 轻量级锁（00） 
→ B 释放 → 可偏向无锁（101）
```

------

#### AQS

> AQS提供了原子性的==管理同步的状态、阻塞线程和唤醒线程==的功能 JUC包下的ReentryLock、Semaphore、CountLatch都是基于AQS实现的 
>
> AQS有几个的概念
>
> - 双向链表队列 （CLH）
>
>   > AQS将每个线程封装成节点放到这个队列中
>
> - int类型的成员变量state
>
>   > 用于表示同步状态 使用volatile修饰保证多线程下的可见性 默认为0 当>0时表示对象锁被占用 获取锁失败的线程加入到双线链表队列中 state也用于记录线程重入次数
>
> - AQS.exclusiveOwnerThread
>
>   > 指向当前持有锁的线程对象

##### ReentryLock

> 内部存在一个类抽象类Sync 这个Sync就是继承了AQS 而Sync存在两个实现类 FairSync和NotFairSync 分别对应着公平锁和非公平锁 在创建Reentry Lock的时候 默认就是创建NotFairSync 如果创建锁传入true 则创建的是FairSync
>
> **加锁**
>
> - 使用CAS将state变量改为1 成功后将AQS.exclusiveOwnerThread设置为获取锁的该线程
> - 获取锁失败的线程会再次CAS判断state变量是否为0以及AQS.exclusiveOwnerThread是否为自身（重入） 如果仍获取锁失败则构建node节点加到队列中 调用LockSupport.park方法将线程挂起
> - 公平锁下 如果队列中存在着节点 则不允许新来的线程修改state变量
>
> **解锁**
>
> - 解锁时候检查AQS.exclusiveOwnerThread是否为自己线程
> - 调用LockSupport.unpark方法唤醒头节点

------

#### ThreadLocal

> 讲ThreadLocal前先讲一下ThreadLocalMap ThreadLocalMap是Thread对象中的一个成员变量 key是弱引用的ThreadLocal对象，而key则是ThreadLocal的值

**ThreadLocalMap**

> ThreadLocalMap底层是一个Entry数组 通过ThreadLocal定位数组索引

**set**

> 当调用ThreadLocal的set方法时 会先获取当前线程下的Thread然后存放在该线程下的ThreadLocalMap中

**get**

> 获取值也是同理 会先获取当前线程下的Thread然后检查该线程下的ThreadLocalMap中是否有该ThreadLocal对象 如果没有则将该ThreadLocal设置进去 并设置value为null

**内存问题**

> ThreadLocalMap对ThreadLocal的引用是弱引用 当线程结束的时候 这个ThreadLocal对象会被回收 但是他的值被ThreadLocalMap持有 生命周期是和Thread绑定的 这个是强引用 因此线程结束的时候要手动remove防止内存泄漏 
>
> 同时ThreadLocal使用的时候一般是设置为static 如果不手动remove 在线程池下可能出现value复用的情况导致出现问题

------

### Spring

1. 实例化

   > Spring启动的时候会扫描配置的包路径下的字节码文件并通过ASM读取字节码获取注解元信息 如果有Component、Service等注解的类就会被注册为Bean 然后执行对象的创建流程（类加载检查、内存分配、初始化零值、对象头设置、执行构造函数）

2. 初始化

   > 在构造函数后执行依赖注入(propertyset) 